{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Glaucoma Segmentation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from collections import defaultdict\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../data/ORIGA/Images_Cropped'\n",
    "MASK_DIR = '../data/ORIGA/Masks_Cropped'\n",
    "LOGS_DIR = '../logs/'\n",
    "CHECKPOINT_DIR = '../checkpoints/'\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 3\n",
    "LAYERS = [32, 64, 128, 256, 512]\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "SAVE_INTERVAL = 10\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "PIN_MEMORY = True if DEVICE == 'cuda' else False\n",
    "LOAD_MODEL = ''\n",
    "USE_WANDB = False\n",
    "DEEP_SUPERVISION = False\n",
    "\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Using device: {DEVICE}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_ds = OrigaDataset(IMAGE_DIR, MASK_DIR, os.listdir(IMAGE_DIR)[:1], A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=1.0),  # rotate by 0, 90, 180, or 270 degrees\n",
    "    A.Rotate(limit=30, p=0.33, border_mode=cv.BORDER_CONSTANT),\n",
    "    A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0]),\n",
    "    ToTensorV2(),\n",
    "]))\n",
    "example_loader = DataLoader(example_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "example_image, example_mask = next(iter(example_loader))\n",
    "print(f'Image shape: {example_image.shape}')\n",
    "print(f'Mask shape: {example_mask.shape}')\n",
    "\n",
    "unique, counts = np.unique(example_mask, return_counts=True)\n",
    "print(f'Unique values and their counts in mask: {dict(zip(unique, counts))}')\n",
    "\n",
    "# Plot example augmented images and masks\n",
    "fig, ax = plt.subplots(3, 6, figsize=(12, 6))\n",
    "ax = ax.ravel()\n",
    "for i in range(0, 3 * 6, 2):\n",
    "    batch = next(iter(example_loader))\n",
    "    images, masks = batch\n",
    "    image, mask = images[0], masks[0]\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    mask = mask.numpy()\n",
    "    ax[i].imshow(image)\n",
    "    ax[i].axis('off')\n",
    "    ax[i + 1].imshow(mask, cmap='gray')\n",
    "    ax[i + 1].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=1.0),\n",
    "    # A.Rotate(limit=30, p=0.25, border_mode=cv.BORDER_CONSTANT),\n",
    "    # A.Normalize(mean=ORIGA_MEANS, std=ORIGA_STDS),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    # A.Normalize(mean=ORIGA_MEANS, std=ORIGA_STDS),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_ds, val_ds, test_ds = load_origa(\n",
    "    IMAGE_DIR, MASK_DIR, train_transform, val_transform, val_transform,\n",
    "    train_size=0.7, val_size=0.15, test_size=0.15,\n",
    "    # train_size=0.01, val_size=0.01, test_size=0.98,\n",
    ")\n",
    "\n",
    "print(f'Train size: {len(train_ds)}')\n",
    "print(f'Validation size: {len(val_ds)}')\n",
    "print(f'Test size: {len(test_ds)}')\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize model, loss, optimizer, scheduler, scaler, ...\n",
    "model = UNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "# model = UNetPlusPlus(in_channels=3, out_channels=3, features=LAYERS, deep_supervision=DEEP_SUPERVISION).to(DEVICE)\n",
    "# model = UNet3Plus(in_channels=3, out_channels=3, features=LAYERS, deep_supervision=DEEP_SUPERVISION).to(DEVICE)\n",
    "\n",
    "# model = AttentionUNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "# model = InceptionUNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "\n",
    "# model = ResUNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "# model = RUNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "# model = R2UNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "\n",
    "# model = SqueezeUNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "\n",
    "# model = R2AttentionUNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "# model = R2UNetPlusPlus(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "\n",
    "# model = ResAttentionUNetPlusPlus(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "# model = RefUNet3PlusCBAM(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()  # softmax layer is already included inside nn.CrossEntropyLoss()\n",
    "criterion = DiceLoss(num_classes=3, device=DEVICE, class_weights=[1.0, 1.0, 1.0])\n",
    "# criterion = IoULoss(num_classes=3, device=DEVICE, class_weights=[1.0, 1.0, 1.0])\n",
    "# criterion = FocalLoss(alpha=0.25, gamma=2)\n",
    "# criterion = TverskyLoss(num_classes=3, alpha=0.5, beta=0.5, class_weights=[1.0, 1.0, 1.0], device=DEVICE)\n",
    "# criterion = FocalTverskyLoss(num_classes=3, alpha=0.5, beta=0.5, gamma=1.0,\n",
    "#                              class_weights=[1.0, 1.0, 1.0], device=DEVICE)\n",
    "\n",
    "# scheduler = None\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "scaler = None\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    load_checkpoint(LOAD_MODEL, model, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = train(\n",
    "    model, criterion, optimizer, EPOCHS, DEVICE, train_loader, val_loader, scheduler, scaler,\n",
    "    save_interval=SAVE_INTERVAL, early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "    log_to_wandb=USE_WANDB, log_dir=LOGS_DIR, checkpoint_dir=CHECKPOINT_DIR,\n",
    "    save_best_model=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "used_metrics = sorted([m[6:] for m in hist.keys() if m.startswith('train_')])\n",
    "fig, ax = plt.subplots(4, 4, figsize=(14, 8))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate(used_metrics):\n",
    "    ax[i].plot(hist[f'train_{metric}'], label=f'train')\n",
    "    ax[i].plot(hist[f'val_{metric}'], label=f'val')\n",
    "    ax[i].set_title(metric[0].upper() + metric[1:].replace('_', ' '))\n",
    "    if metric != 'loss':\n",
    "        ax[i].set_ylim(top=1)\n",
    "    ax[i].legend()\n",
    "\n",
    "for ax in ax[len(used_metrics):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = evaluate(model, criterion, DEVICE, test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_results_from_loader(test_loader, model, DEVICE, types='all', n_samples=5, save_path=f'{LOGS_DIR}/evaluation.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Work in progress"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), CHECKPOINT_DIR + 'model.pth')\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_DIR + 'model.pth')\n",
    "model = UNet(in_channels=3, out_channels=3).to(DEVICE)\n",
    "model.load_state_dict(checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "\n",
    "class HausdorffLoss(nn.Module):\n",
    "    def __init__(self, num_classes=3, ignore_index=0):\n",
    "        super(HausdorffLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_index = ignore_index\n",
    "        self.alpha = 2\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        loss = 0\n",
    "\n",
    "        for class_idx in range(self.num_classes):\n",
    "            if class_idx == self.ignore_index:\n",
    "                continue\n",
    "\n",
    "            pred_class = (preds >= class_idx).float().requires_grad_(True)\n",
    "            target_class = (target >= class_idx).float().requires_grad_(True)\n",
    "\n",
    "            pred_dist = self.compute_distance_map(pred_class)\n",
    "            target_dist = self.compute_distance_map(target_class)\n",
    "\n",
    "            forward_hd = torch.max(pred_dist * target_class)\n",
    "            backward_hd = torch.max(target_dist * pred_class)\n",
    "\n",
    "            hausdorff_dist = torch.pow(forward_hd, self.alpha) + torch.pow(backward_hd, self.alpha)\n",
    "            hausdorff_loss = torch.abs(pred_class - target_class) * hausdorff_dist\n",
    "\n",
    "            loss += hausdorff_loss.mean()\n",
    "\n",
    "        loss /= (self.num_classes - 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_distance_map(self, mask):\n",
    "        mask_np = mask.squeeze().detach().cpu().numpy().astype(np.float32)\n",
    "        dist_map = np.zeros_like(mask_np, dtype=np.float32)\n",
    "\n",
    "        for i in range(mask_np.shape[0]):\n",
    "            dist_map[i] += distance_transform_edt(mask_np[i])\n",
    "            dist_map[i] += distance_transform_edt(1 - mask_np[i])\n",
    "\n",
    "        # _, ax = plt.subplots(1, mask_np.shape[0], figsize=(10, 10))\n",
    "        # for i in range(dist_map.shape[0]):\n",
    "        #     ax[i].imshow(dist_map[i])\n",
    "        # plt.show()\n",
    "\n",
    "        dist_map = torch.from_numpy(dist_map).unsqueeze(0).to(mask.device)\n",
    "\n",
    "        return dist_map\n",
    "\n",
    "\n",
    "class HausdorffDTLoss(nn.Module):\n",
    "    \"\"\"Binary Hausdorff loss based on distance transform\"\"\"\n",
    "\n",
    "    def __init__(self, alpha=2.0, **kwargs):\n",
    "        super(HausdorffDTLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def distance_field(self, img: np.ndarray) -> np.ndarray:\n",
    "        field = np.zeros_like(img)\n",
    "\n",
    "        for i in range(len(img)):\n",
    "            fg_mask = img[i] > 0.5\n",
    "\n",
    "            if fg_mask.any():\n",
    "                bg_mask = ~fg_mask\n",
    "\n",
    "                fg_dist = distance_transform_edt(fg_mask)\n",
    "                bg_dist = distance_transform_edt(bg_mask)\n",
    "\n",
    "                field[i] = fg_dist + bg_dist\n",
    "\n",
    "        return field\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Uses one binary channel: 1 - fg, 0 - bg\n",
    "        pred: (b, 1, x, y, z) or (b, 1, x, y)\n",
    "        target: (b, 1, x, y, z) or (b, 1, x, y)\n",
    "        \"\"\"\n",
    "\n",
    "        pred_dt = torch.from_numpy(self.distance_field(pred.cpu().numpy())).float()\n",
    "        target_dt = torch.from_numpy(self.distance_field(target.cpu().numpy())).float()\n",
    "\n",
    "        pred_error = (pred - target) ** 2\n",
    "        distance = pred_dt ** self.alpha + target_dt ** self.alpha\n",
    "\n",
    "        dt_field = pred_error * distance\n",
    "        return dt_field.mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hausdorff_loss = HausdorffLoss()\n",
    "\n",
    "# images, masks = next(iter(train_loader))\n",
    "# images = images.float().to(DEVICE)\n",
    "# masks = masks.long().to(DEVICE)\n",
    "\n",
    "print(f'{images.shape = }')\n",
    "print(f'{masks.shape = }')\n",
    "\n",
    "logits = model(images)\n",
    "print(f'{logits.shape = }')\n",
    "loss = hausdorff_loss(logits, masks)\n",
    "print(f'Hausdorff loss: {loss.item()}, {loss.shape = }')\n",
    "\n",
    "loss.backward()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BoundaryLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoundaryLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        predictions = torch.argmax(probs, dim=1)\n",
    "\n",
    "        # Compute the boundary maps for both prediction and target\n",
    "        pred_boundary = self.compute_boundary_map(predictions)\n",
    "        target_boundary = self.compute_boundary_map(target)\n",
    "\n",
    "        # Calculate the boundary loss\n",
    "        loss = torch.mean((pred_boundary - target_boundary) ** 2)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_boundary_map(self, mask):\n",
    "        # Define the horizontal and vertical sobel filters\n",
    "        sobel_x = torch.Tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]]).to(DEVICE)\n",
    "        sobel_y = torch.Tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]).to(DEVICE)\n",
    "\n",
    "        # Compute the horizontal and vertical gradients using the sobel filters\n",
    "        G_x = F.conv2d(mask, sobel_x, padding=1)\n",
    "        G_y = F.conv2d(mask, sobel_y, padding=1)\n",
    "\n",
    "        # Calculate the magnitude of the gradient\n",
    "        G = torch.sqrt(torch.pow(G_x, 2) + torch.pow(G_y, 2))\n",
    "\n",
    "        # Normalize the gradient magnitude\n",
    "        G = G / torch.max(G)\n",
    "\n",
    "        return G"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "lambda_boundary = 0.5\n",
    "\n",
    "# Instantiate the boundary loss\n",
    "boundary_loss = BoundaryLoss()\n",
    "\n",
    "# Example usage within the training loop\n",
    "for images, masks in val_loader:\n",
    "    images = images.float().to(DEVICE)\n",
    "    masks = masks.long().to(DEVICE)\n",
    "\n",
    "    # Forward pass to obtain the predicted segmentation mask\n",
    "    logits = model(images)\n",
    "\n",
    "    # Compute the segmentation loss (e.g., cross-entropy)\n",
    "    seg_loss = cross_entropy(logits, masks)\n",
    "\n",
    "    # Compute the boundary loss\n",
    "    bnd_loss = boundary_loss(logits, masks)\n",
    "\n",
    "    # Combine the losses (adjust the weights if necessary)\n",
    "    total_loss = seg_loss + lambda_boundary * bnd_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# images = images.float().to(DEVICE)\n",
    "# masks = masks.long().to(DEVICE)\n",
    "# outputs = model(images)\n",
    "# preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "metrics = get_performance_metrics(masks, preds)\n",
    "metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "old_metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
