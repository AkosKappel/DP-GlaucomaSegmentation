{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Glaucoma Segmentation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from collections import defaultdict\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../data/ORIGA/Images_Cropped'\n",
    "MASK_DIR = '../data/ORIGA/Masks_Cropped'\n",
    "LOGS_DIR = '../logs'\n",
    "CHECKPOINT_DIR = '../checkpoints'\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 3\n",
    "LAYERS = [32, 64, 128, 256, 512]\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "SAVE_INTERVAL = 10\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "PIN_MEMORY = True if DEVICE == 'cuda' else False\n",
    "LOAD_MODEL = ''\n",
    "USE_WANDB = False\n",
    "\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Using device: {DEVICE}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    'image_size': (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'epochs': EPOCHS,\n",
    "    'dataset': 'ORIGA',\n",
    "    'layers': LAYERS,\n",
    "}\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "if USE_WANDB:\n",
    "    wandb.init(project='DP-Glaucoma', config=config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize model, loss, optimizer, scheduler, ...\n",
    "model = UNet(in_channels=3, out_channels=3, features=LAYERS).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()  # softmax layer is already included inside nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = None\n",
    "scaler = None\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    load_checkpoint(LOAD_MODEL, model, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_ds = OrigaDataset(IMAGE_DIR, MASK_DIR, os.listdir(IMAGE_DIR)[:1], A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=1.0),  # rotate by 0, 90, 180, or 270 degrees\n",
    "    A.Rotate(limit=30, p=0.33, border_mode=cv.BORDER_CONSTANT),\n",
    "    A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0]),\n",
    "    ToTensorV2(),\n",
    "]))\n",
    "example_loader = DataLoader(example_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "example_image, example_mask = next(iter(example_loader))\n",
    "print(f'Image shape: {example_image.shape}')\n",
    "print(f'Mask shape: {example_mask.shape}')\n",
    "\n",
    "unique, counts = np.unique(example_mask, return_counts=True)\n",
    "print(f'Unique values and their counts in mask: {dict(zip(unique, counts))}')\n",
    "\n",
    "# Plot example augmented images and masks\n",
    "fig, ax = plt.subplots(3, 6, figsize=(12, 6))\n",
    "ax = ax.ravel()\n",
    "for i in range(0, 3 * 6, 2):\n",
    "    batch = next(iter(example_loader))\n",
    "    images, masks = batch\n",
    "    image, mask = images[0], masks[0]\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    mask = mask.numpy()\n",
    "    ax[i].imshow(image)\n",
    "    ax[i].axis('off')\n",
    "    ax[i + 1].imshow(mask, cmap='gray')\n",
    "    ax[i + 1].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=1.0),\n",
    "    A.Rotate(limit=30, p=0.25, border_mode=cv.BORDER_CONSTANT),\n",
    "    A.Normalize(mean=ORIGA_MEANS, std=ORIGA_STDS),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.Normalize(mean=ORIGA_MEANS, std=ORIGA_STDS),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_ds, val_ds, test_ds = load_origa(\n",
    "    IMAGE_DIR, MASK_DIR, train_transform, val_transform, val_transform,\n",
    "    train_size=0.7, val_size=0.15, test_size=0.15,\n",
    "    # train_size=0.01, val_size=0.01, test_size=0.98,\n",
    ")\n",
    "\n",
    "print(f'Train size: {len(train_ds)}')\n",
    "print(f'Validation size: {len(val_ds)}')\n",
    "print(f'Test size: {len(test_ds)}')\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = train(\n",
    "    model, criterion, optimizer, EPOCHS, DEVICE, train_loader, val_loader, scheduler, scaler,\n",
    "    save_interval=SAVE_INTERVAL, early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "    log_to_wandb=USE_WANDB, log_dir=LOGS_DIR, checkpoint_dir=CHECKPOINT_DIR,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "fig, ax = plt.subplots(4, 2, figsize=(10, 12))\n",
    "ax = ax.ravel()\n",
    "for i, metric in enumerate(['dice', 'iou', 'accuracy', 'precision', 'sensitivity', 'specificity', 'loss']):\n",
    "    ax[i].plot(hist[f'train_{metric}'], label=f'train')\n",
    "    ax[i].plot(hist[f'val_{metric}'], label=f'val')\n",
    "    ax[i].set_title(metric[0].upper() + metric[1:])\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "    ax[i].set_ylabel(metric)\n",
    "    if metric != 'loss':\n",
    "        ax[i].set_ylim(top=1)\n",
    "    ax[i].legend()\n",
    "ax[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, device, loader):\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    history = defaultdict(list)\n",
    "    total = len(loader)\n",
    "    loop = tqdm(loader, total=total, leave=True, desc='Evaluating')\n",
    "    mean_metrics = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, masks) in enumerate(loop):\n",
    "            images = images.to(device=device)\n",
    "            masks = masks.to(device=device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks.long())\n",
    "\n",
    "            # performance metrics\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            metrics = get_performance_metrics(masks.cpu(), preds.cpu())\n",
    "\n",
    "            # update history\n",
    "            history['loss'].append(loss.item())\n",
    "            for k, v in metrics.items():\n",
    "                history[k].append(v)\n",
    "\n",
    "            # show mean metrics after every batch\n",
    "            mean_metrics = {k: np.mean(v) for k, v in history.items()}\n",
    "            loop.set_postfix(**mean_metrics)\n",
    "\n",
    "    return mean_metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = evaluate(model, criterion, DEVICE, test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_results_from_loader(test_loader, model, DEVICE, f'{LOGS_DIR}/eval.png', mean=ORIGA_MEANS, std=ORIGA_STDS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
