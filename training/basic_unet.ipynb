{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# U-Net for Glaucoma Detection\n",
    "\n",
    "This notebook contains the code for training a simple **U-Net** model for glaucoma detection on the ORIGA dataset.\n",
    "The results are mainly for creating a baseline for further experiments.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from collections import defaultdict\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from models.unet import UNet\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../data/ORIGA/Images_Cropped'\n",
    "MASK_DIR = '../data/ORIGA/Masks_Cropped'\n",
    "LOGS_DIR = '../logs'\n",
    "CHECKPOINT_DIR = '../checkpoints'\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 3\n",
    "LAYERS = [32, 64, 128, 256]\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "SAVE_INTERVAL = 10\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "PIN_MEMORY = True if DEVICE == 'cuda' else False\n",
    "LOAD_MODEL = ''\n",
    "USE_WANDB = False\n",
    "\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "CLASS_LABELS = {\n",
    "    0: 'Background',\n",
    "    1: 'Optic Disc',\n",
    "    2: 'Optic Cup',\n",
    "}\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Using device: {DEVICE}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    'image_size': (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'epochs': EPOCHS,\n",
    "    'dataset': 'ORIGA',\n",
    "    'layers': LAYERS,\n",
    "}\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "if USE_WANDB:\n",
    "    wandb.init(project='DP-Glaucoma', config=config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize model, loss, optimizer, scheduler, ...\n",
    "model = UNet(in_channels=3, out_channels=3, features=LAYERS)\n",
    "criterion = nn.CrossEntropyLoss()  # softmax layer is already included inside nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    load_checkpoint(LOAD_MODEL, model, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_ds = OrigaDataset(IMAGE_DIR, MASK_DIR, os.listdir(IMAGE_DIR)[:1], A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=1.0),  # rotate by 0, 90, 180, or 270 degrees\n",
    "    A.Rotate(limit=30, p=0.33, border_mode=cv.BORDER_CONSTANT),\n",
    "    A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0]),\n",
    "    ToTensorV2(),\n",
    "]))\n",
    "example_loader = DataLoader(example_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "example_image, example_mask = next(iter(example_loader))\n",
    "print(f'Image shape: {example_image.shape}')\n",
    "print(f'Mask shape: {example_mask.shape}')\n",
    "\n",
    "unique, counts = np.unique(example_mask, return_counts=True)\n",
    "print(f'Unique values and their counts in mask: {dict(zip(unique, counts))}')\n",
    "\n",
    "# Plot example augmented images and masks\n",
    "fig, ax = plt.subplots(3, 6, figsize=(12, 6))\n",
    "ax = ax.ravel()\n",
    "for i in range(0, 3 * 6, 2):\n",
    "    batch = next(iter(example_loader))\n",
    "    images, masks = batch\n",
    "    image, mask = images[0], masks[0]\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    mask = mask.numpy()\n",
    "    ax[i].imshow(image)\n",
    "    ax[i].axis('off')\n",
    "    ax[i + 1].imshow(mask, cmap='gray')\n",
    "    ax[i + 1].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=1.0),\n",
    "    A.Rotate(limit=30, p=0.25, border_mode=cv.BORDER_CONSTANT),\n",
    "    A.Normalize(mean=ORIGA_MEANS, std=ORIGA_STDS),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    A.Normalize(mean=ORIGA_MEANS, std=ORIGA_STDS),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_ds, val_ds, test_ds = load_origa(\n",
    "    IMAGE_DIR, MASK_DIR, train_transform, val_transform, val_transform,\n",
    "    train_size=0.7, val_size=0.15, test_size=0.15,\n",
    "    # train_size=0.01, val_size=0.01, test_size=0.98,\n",
    ")\n",
    "\n",
    "print(f'Train size: {len(train_ds)}')\n",
    "print(f'Validation size: {len(val_ds)}')\n",
    "print(f'Test size: {len(test_ds)}')\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, device, loader):\n",
    "    model.train()\n",
    "    history = defaultdict(list)\n",
    "    total = len(loader)\n",
    "    loop = tqdm(loader, total=total, leave=True, desc='Training')\n",
    "    mean_metrics = None\n",
    "\n",
    "    # iterate once over all the batches in the training data loader\n",
    "    for batch_idx, (images, masks) in enumerate(loop):\n",
    "        # move data to device\n",
    "        images = images.to(device=device)\n",
    "        masks = masks.to(device=device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.long())\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate metrics\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        metrics = get_performance_metrics(masks.cpu(), preds.cpu())\n",
    "\n",
    "        # update training history\n",
    "        history['loss'].append(loss.item())\n",
    "        for k, v in metrics.items():\n",
    "            history[k].append(v)\n",
    "\n",
    "        # display average metrics at the end of the epoch\n",
    "        last_batch = batch_idx == total - 1\n",
    "        if last_batch:\n",
    "            mean_metrics = {k: np.mean(v) for k, v in history.items()}\n",
    "            loop.set_postfix(**mean_metrics)\n",
    "\n",
    "    return mean_metrics\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, criterion, device, loader):\n",
    "    model.eval()\n",
    "    history = defaultdict(list)\n",
    "    total = len(loader)\n",
    "    loop = tqdm(loader, total=total, leave=True, desc='Validation')\n",
    "    mean_metrics = None\n",
    "\n",
    "    # disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # iterate once over all batches in the validation dataset\n",
    "        for batch_idx, (images, masks) in enumerate(loop):\n",
    "            images = images.to(device=device)\n",
    "            masks = masks.to(device=device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks.long())\n",
    "\n",
    "            # calculate metrics\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            metrics = get_performance_metrics(masks.cpu(), preds.cpu())\n",
    "\n",
    "            # update validation history\n",
    "            history['loss'].append(loss.item())\n",
    "            for k, v in metrics.items():\n",
    "                history[k].append(v)\n",
    "\n",
    "            # show summary after last batch\n",
    "            last_batch = batch_idx == total - 1\n",
    "            if last_batch:\n",
    "                mean_metrics = {k: np.mean(v) for k, v in history.items()}\n",
    "                loop.set_postfix(**mean_metrics)\n",
    "\n",
    "    return mean_metrics\n",
    "\n",
    "\n",
    "def log_progress(model, loader, optimizer, history, epoch, device, part='validation'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        images, masks = batch\n",
    "\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        images = images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        masks = masks.cpu().numpy()\n",
    "        preds = preds.cpu().numpy()\n",
    "\n",
    "    if USE_WANDB:\n",
    "        for i, image in enumerate(images):\n",
    "            mask = masks[i]\n",
    "            pred = preds[i]\n",
    "            seg_img = wandb.Image(image, masks={\n",
    "                'prediction': {\n",
    "                    'mask_data': pred,\n",
    "                    'class_labels': CLASS_LABELS,\n",
    "                },\n",
    "                'ground_truth': {\n",
    "                    'mask_data': mask,\n",
    "                    'class_labels': CLASS_LABELS,\n",
    "                },\n",
    "            })\n",
    "            wandb.log({f'Segmentation results ({part})': seg_img}, step=epoch)\n",
    "            break\n",
    "\n",
    "    file = f'{LOGS_DIR}/epoch{epoch}.png'\n",
    "    plot_results(images, masks, preds, save_path=file, show=False)\n",
    "\n",
    "    if USE_WANDB:\n",
    "        wandb.log({f'Plotted results ({part})': wandb.Image(file)}, step=epoch)\n",
    "        wandb.log({'learning_rate': optimizer.param_groups[0]['lr']}, step=epoch)\n",
    "        wandb.log({k: v[-1] for k, v in history.items()}, step=epoch)\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, epochs, device, train_loader, val_loader=None, scheduler=None,\n",
    "          early_stopping_patience=0, save_best_model=True, save_interval=0):\n",
    "    history = defaultdict(list)\n",
    "    best_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    model = model.to(device=device)\n",
    "    if USE_WANDB:\n",
    "        wandb.watch(model, criterion)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'Epoch {epoch}:')\n",
    "\n",
    "        # training\n",
    "        train_metrics = train_one_epoch(model, criterion, optimizer, device, train_loader)\n",
    "        for k, v in train_metrics.items():\n",
    "            history[f'train_{k}'].append(v)\n",
    "\n",
    "        # skip validation part if data loader was not provided\n",
    "        if val_loader is not None:\n",
    "            # validation\n",
    "            val_metrics = validate_one_epoch(model, criterion, device, val_loader)\n",
    "            for k, v in val_metrics.items():\n",
    "                history[f'val_{k}'].append(v)\n",
    "\n",
    "        val_loss = history['val_loss'][-1] if val_loader is not None else history['train_loss'][-1]\n",
    "\n",
    "        # learning rate scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        # log metrics locally and to wandb\n",
    "        loader = val_loader if val_loader else train_loader\n",
    "        log_progress(model, loader, optimizer, history, epoch, device)\n",
    "\n",
    "        # save checkpoint after every few epochs\n",
    "        if save_interval and epoch % save_interval == 0:\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }\n",
    "            save_checkpoint(checkpoint, filename=f'checkpoint-epoch{epoch}.pth.tar', checkpoint_dir=CHECKPOINT_DIR)\n",
    "\n",
    "        # early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_without_improvement = 0\n",
    "\n",
    "            if save_best_model:\n",
    "                checkpoint = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }\n",
    "                save_checkpoint(checkpoint, filename='best-model.pth.tar', checkpoint_dir=CHECKPOINT_DIR)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if early_stopping_patience and epochs_without_improvement == early_stopping_patience:\n",
    "                print(f'Early stopping: best validation loss = {best_loss:.4f} at epoch {best_epoch}')\n",
    "                break\n",
    "\n",
    "    return history\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = train(model, criterion, optimizer, EPOCHS, DEVICE, train_loader, val_loader, scheduler,\n",
    "             save_interval=SAVE_INTERVAL, early_stopping_patience=EARLY_STOPPING_PATIENCE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "fig, ax = plt.subplots(4, 2, figsize=(10, 12))\n",
    "ax = ax.ravel()\n",
    "for i, metric in enumerate(['dice', 'iou', 'accuracy', 'precision', 'sensitivity', 'specificity', 'loss']):\n",
    "    ax[i].plot(hist[f'train_{metric}'], label=f'train')\n",
    "    ax[i].plot(hist[f'val_{metric}'], label=f'val')\n",
    "    ax[i].set_title(metric[0].upper() + metric[1:])\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "    ax[i].set_ylabel(metric)\n",
    "    if metric != 'loss':\n",
    "        ax[i].set_ylim(top=1)\n",
    "    ax[i].legend()\n",
    "ax[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, device, loader):\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    history = defaultdict(list)\n",
    "    total = len(loader)\n",
    "    loop = tqdm(loader, total=total, leave=True, desc='Evaluating')\n",
    "    mean_metrics = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, masks) in enumerate(loop):\n",
    "            images = images.to(device=device)\n",
    "            masks = masks.to(device=device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks.long())\n",
    "\n",
    "            # performance metrics\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            metrics = get_performance_metrics(masks.cpu(), preds.cpu())\n",
    "\n",
    "            # update history\n",
    "            history['loss'].append(loss.item())\n",
    "            for k, v in metrics.items():\n",
    "                history[k].append(v)\n",
    "\n",
    "            # show mean metrics after every batch\n",
    "            mean_metrics = {k: np.mean(v) for k, v in history.items()}\n",
    "            loop.set_postfix(**mean_metrics)\n",
    "\n",
    "    return mean_metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = evaluate(model, criterion, DEVICE, test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_results_from_loader(test_loader, model, DEVICE, f'{LOGS_DIR}/eval.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
