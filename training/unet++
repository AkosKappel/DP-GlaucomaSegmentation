digraph {
	graph [size="92.85,92.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2452443995712 [label="
 (1, 3, 128, 128)" fillcolor=darkolivegreen1]
	2454388753552 [label=ConvolutionBackward0]
	2454388762432 -> 2454388753552
	2454388762432 [label=ReluBackward0]
	2454388766032 -> 2454388762432
	2454388766032 [label=NativeBatchNormBackward0]
	2454388753408 -> 2454388766032
	2454388753408 [label=ConvolutionBackward0]
	2454388761856 -> 2454388753408
	2454388761856 [label=ReluBackward0]
	2454388765936 -> 2454388761856
	2454388765936 [label=NativeBatchNormBackward0]
	2454388763104 -> 2454388765936
	2454388763104 [label=ConvolutionBackward0]
	2454388763440 -> 2454388763104
	2454388763440 [label=CatBackward0]
	2454388764736 -> 2454388763440
	2454388764736 [label=ReluBackward0]
	2454388768480 -> 2454388764736
	2454388768480 [label=NativeBatchNormBackward0]
	2454388764928 -> 2454388768480
	2454388764928 [label=ConvolutionBackward0]
	2454388762720 -> 2454388764928
	2454388762720 [label=ReluBackward0]
	2454388765264 -> 2454388762720
	2454388765264 [label=NativeBatchNormBackward0]
	2454388764544 -> 2454388765264
	2454388764544 [label=ConvolutionBackward0]
	2454388762480 -> 2454388764544
	2454377488176 [label="rows.0.0.conv.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	2454377488176 -> 2454388762480
	2454388762480 [label=AccumulateGrad]
	2454388764880 -> 2454388765264
	2452443726688 [label="rows.0.0.conv.1.weight
 (32)" fillcolor=lightblue]
	2452443726688 -> 2454388764880
	2454388764880 [label=AccumulateGrad]
	2454388762816 -> 2454388765264
	2452443726768 [label="rows.0.0.conv.1.bias
 (32)" fillcolor=lightblue]
	2452443726768 -> 2454388762816
	2454388762816 [label=AccumulateGrad]
	2454388767856 -> 2454388764928
	2452443727088 [label="rows.0.0.conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2452443727088 -> 2454388767856
	2454388767856 [label=AccumulateGrad]
	2454388759120 -> 2454388768480
	2452443727168 [label="rows.0.0.conv.4.weight
 (32)" fillcolor=lightblue]
	2452443727168 -> 2454388759120
	2454388759120 [label=AccumulateGrad]
	2454388763728 -> 2454388768480
	2452443727248 [label="rows.0.0.conv.4.bias
 (32)" fillcolor=lightblue]
	2452443727248 -> 2454388763728
	2454388763728 [label=AccumulateGrad]
	2454388765552 -> 2454388763440
	2454388765552 [label=ReluBackward0]
	2454388765360 -> 2454388765552
	2454388765360 [label=NativeBatchNormBackward0]
	2454388764592 -> 2454388765360
	2454388764592 [label=ConvolutionBackward0]
	2454389613680 -> 2454388764592
	2454389613680 [label=ReluBackward0]
	2454389615744 -> 2454389613680
	2454389615744 [label=NativeBatchNormBackward0]
	2454389614976 -> 2454389615744
	2454389614976 [label=ConvolutionBackward0]
	2454389617040 -> 2454389614976
	2454389617040 [label=CatBackward0]
	2454388764736 -> 2454389617040
	2454389619488 -> 2454389617040
	2454389619488 [label=UpsampleBilinear2DBackward0]
	2454389616896 -> 2454389619488
	2454389616896 [label=ReluBackward0]
	2454389616416 -> 2454389616896
	2454389616416 [label=NativeBatchNormBackward0]
	2454377553424 -> 2454389616416
	2454377553424 [label=ConvolutionBackward0]
	2454389874768 -> 2454377553424
	2454389874768 [label=ReluBackward0]
	2454389874624 -> 2454389874768
	2454389874624 [label=NativeBatchNormBackward0]
	2454389874528 -> 2454389874624
	2454389874528 [label=ConvolutionBackward0]
	2454389874336 -> 2454389874528
	2454389874336 [label=MaxPool2DWithIndicesBackward0]
	2454388764736 -> 2454389874336
	2454389874384 -> 2454389874528
	2452443732768 [label="rows.1.0.conv.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2452443732768 -> 2454389874384
	2454389874384 [label=AccumulateGrad]
	2454389874576 -> 2454389874624
	2452443732848 [label="rows.1.0.conv.1.weight
 (64)" fillcolor=lightblue]
	2452443732848 -> 2454389874576
	2454389874576 [label=AccumulateGrad]
	2454389874720 -> 2454389874624
	2452443732928 [label="rows.1.0.conv.1.bias
 (64)" fillcolor=lightblue]
	2452443732928 -> 2454389874720
	2454389874720 [label=AccumulateGrad]
	2454389874816 -> 2454377553424
	2452443733408 [label="rows.1.0.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2452443733408 -> 2454389874816
	2454389874816 [label=AccumulateGrad]
	2454389617664 -> 2454389616416
	2452443733488 [label="rows.1.0.conv.4.weight
 (64)" fillcolor=lightblue]
	2452443733488 -> 2454389617664
	2454389617664 [label=AccumulateGrad]
	2454389620352 -> 2454389616416
	2452443733568 [label="rows.1.0.conv.4.bias
 (64)" fillcolor=lightblue]
	2452443733568 -> 2454389620352
	2454389620352 [label=AccumulateGrad]
	2454389618864 -> 2454389614976
	2452443727648 [label="rows.0.1.conv.0.weight
 (32, 96, 3, 3)" fillcolor=lightblue]
	2452443727648 -> 2454389618864
	2454389618864 [label=AccumulateGrad]
	2454389618672 -> 2454389615744
	2452443727728 [label="rows.0.1.conv.1.weight
 (32)" fillcolor=lightblue]
	2452443727728 -> 2454389618672
	2454389618672 [label=AccumulateGrad]
	2454389615888 -> 2454389615744
	2452443727808 [label="rows.0.1.conv.1.bias
 (32)" fillcolor=lightblue]
	2452443727808 -> 2454389615888
	2454389615888 [label=AccumulateGrad]
	2454389618480 -> 2454388764592
	2452443728288 [label="rows.0.1.conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2452443728288 -> 2454389618480
	2454389618480 [label=AccumulateGrad]
	2454388763776 -> 2454388765360
	2452443728368 [label="rows.0.1.conv.4.weight
 (32)" fillcolor=lightblue]
	2452443728368 -> 2454388763776
	2454388763776 [label=AccumulateGrad]
	2454388766848 -> 2454388765360
	2452443728448 [label="rows.0.1.conv.4.bias
 (32)" fillcolor=lightblue]
	2452443728448 -> 2454388766848
	2454388766848 [label=AccumulateGrad]
	2454388766080 -> 2454388763440
	2454388766080 [label=ReluBackward0]
	2454388762768 -> 2454388766080
	2454388762768 [label=NativeBatchNormBackward0]
	2454389620160 -> 2454388762768
	2454389620160 [label=ConvolutionBackward0]
	2454389616656 -> 2454389620160
	2454389616656 [label=ReluBackward0]
	2454389874432 -> 2454389616656
	2454389874432 [label=NativeBatchNormBackward0]
	2454389874672 -> 2454389874432
	2454389874672 [label=ConvolutionBackward0]
	2454389874144 -> 2454389874672
	2454389874144 [label=CatBackward0]
	2454388764736 -> 2454389874144
	2454388765552 -> 2454389874144
	2454389874000 -> 2454389874144
	2454389874000 [label=UpsampleBilinear2DBackward0]
	2454389873904 -> 2454389874000
	2454389873904 [label=ReluBackward0]
	2454389868576 -> 2454389873904
	2454389868576 [label=NativeBatchNormBackward0]
	2454389868672 -> 2454389868576
	2454389868672 [label=ConvolutionBackward0]
	2454389868480 -> 2454389868672
	2454389868480 [label=ReluBackward0]
	2454389875008 -> 2454389868480
	2454389875008 [label=NativeBatchNormBackward0]
	2454389875056 -> 2454389875008
	2454389875056 [label=ConvolutionBackward0]
	2454389875296 -> 2454389875056
	2454389875296 [label=CatBackward0]
	2454389616896 -> 2454389875296
	2454389875440 -> 2454389875296
	2454389875440 [label=UpsampleBilinear2DBackward0]
	2454389875536 -> 2454389875440
	2454389875536 [label=ReluBackward0]
	2454389875632 -> 2454389875536
	2454389875632 [label=NativeBatchNormBackward0]
	2454389875728 -> 2454389875632
	2454389875728 [label=ConvolutionBackward0]
	2454389875920 -> 2454389875728
	2454389875920 [label=ReluBackward0]
	2454389876064 -> 2454389875920
	2454389876064 [label=NativeBatchNormBackward0]
	2454389876160 -> 2454389876064
	2454389876160 [label=ConvolutionBackward0]
	2454389876352 -> 2454389876160
	2454389876352 [label=MaxPool2DWithIndicesBackward0]
	2454389616896 -> 2454389876352
	2454389876304 -> 2454389876160
	2452443737808 [label="rows.2.0.conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2452443737808 -> 2454389876304
	2454389876304 [label=AccumulateGrad]
	2454389876112 -> 2454389876064
	2452443737888 [label="rows.2.0.conv.1.weight
 (128)" fillcolor=lightblue]
	2452443737888 -> 2454389876112
	2454389876112 [label=AccumulateGrad]
	2454389875968 -> 2454389876064
	2452443737968 [label="rows.2.0.conv.1.bias
 (128)" fillcolor=lightblue]
	2452443737968 -> 2454389875968
	2454389875968 [label=AccumulateGrad]
	2454389875872 -> 2454389875728
	2452443738448 [label="rows.2.0.conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2452443738448 -> 2454389875872
	2454389875872 [label=AccumulateGrad]
	2454389875680 -> 2454389875632
	2452443738528 [label="rows.2.0.conv.4.weight
 (128)" fillcolor=lightblue]
	2452443738528 -> 2454389875680
	2454389875680 [label=AccumulateGrad]
	2454389875344 -> 2454389875632
	2452443738608 [label="rows.2.0.conv.4.bias
 (128)" fillcolor=lightblue]
	2452443738608 -> 2454389875344
	2454389875344 [label=AccumulateGrad]
	2454389875248 -> 2454389875056
	2452443734048 [label="rows.1.1.conv.0.weight
 (64, 192, 3, 3)" fillcolor=lightblue]
	2452443734048 -> 2454389875248
	2454389875248 [label=AccumulateGrad]
	2454389875104 -> 2454389875008
	2452443734128 [label="rows.1.1.conv.1.weight
 (64)" fillcolor=lightblue]
	2452443734128 -> 2454389875104
	2454389875104 [label=AccumulateGrad]
	2454389871360 -> 2454389875008
	2452443734208 [label="rows.1.1.conv.1.bias
 (64)" fillcolor=lightblue]
	2452443734208 -> 2454389871360
	2454389871360 [label=AccumulateGrad]
	2454389871408 -> 2454389868672
	2452443734688 [label="rows.1.1.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2452443734688 -> 2454389871408
	2454389871408 [label=AccumulateGrad]
	2454389871456 -> 2454389868576
	2452443734768 [label="rows.1.1.conv.4.weight
 (64)" fillcolor=lightblue]
	2452443734768 -> 2454389871456
	2454389871456 [label=AccumulateGrad]
	2454389874096 -> 2454389868576
	2452443734848 [label="rows.1.1.conv.4.bias
 (64)" fillcolor=lightblue]
	2452443734848 -> 2454389874096
	2454389874096 [label=AccumulateGrad]
	2454389874192 -> 2454389874672
	2452443728928 [label="rows.0.2.conv.0.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2452443728928 -> 2454389874192
	2454389874192 [label=AccumulateGrad]
	2454389874480 -> 2454389874432
	2452443729008 [label="rows.0.2.conv.1.weight
 (32)" fillcolor=lightblue]
	2452443729008 -> 2454389874480
	2454389874480 [label=AccumulateGrad]
	2454389874912 -> 2454389874432
	2452443729088 [label="rows.0.2.conv.1.bias
 (32)" fillcolor=lightblue]
	2452443729088 -> 2454389874912
	2454389874912 [label=AccumulateGrad]
	2454389616848 -> 2454389620160
	2452443729568 [label="rows.0.2.conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2452443729568 -> 2454389616848
	2454389616848 [label=AccumulateGrad]
	2454389616176 -> 2454388762768
	2452443729648 [label="rows.0.2.conv.4.weight
 (32)" fillcolor=lightblue]
	2452443729648 -> 2454389616176
	2454389616176 [label=AccumulateGrad]
	2454389615696 -> 2454388762768
	2452443729728 [label="rows.0.2.conv.4.bias
 (32)" fillcolor=lightblue]
	2452443729728 -> 2454389615696
	2454389615696 [label=AccumulateGrad]
	2454388762192 -> 2454388763440
	2454388762192 [label=ReluBackward0]
	2454389618240 -> 2454388762192
	2454389618240 [label=NativeBatchNormBackward0]
	2454388764208 -> 2454389618240
	2454388764208 [label=ConvolutionBackward0]
	2454389874048 -> 2454388764208
	2454389874048 [label=ReluBackward0]
	2454389875152 -> 2454389874048
	2454389875152 [label=NativeBatchNormBackward0]
	2454389875584 -> 2454389875152
	2454389875584 [label=ConvolutionBackward0]
	2454389875824 -> 2454389875584
	2454389875824 [label=CatBackward0]
	2454388764736 -> 2454389875824
	2454388765552 -> 2454389875824
	2454388766080 -> 2454389875824
	2454389876016 -> 2454389875824
	2454389876016 [label=UpsampleBilinear2DBackward0]
	2454389876448 -> 2454389876016
	2454389876448 [label=ReluBackward0]
	2454389876544 -> 2454389876448
	2454389876544 [label=NativeBatchNormBackward0]
	2454389876640 -> 2454389876544
	2454389876640 [label=ConvolutionBackward0]
	2454389876832 -> 2454389876640
	2454389876832 [label=ReluBackward0]
	2454389876976 -> 2454389876832
	2454389876976 [label=NativeBatchNormBackward0]
	2454389877072 -> 2454389876976
	2454389877072 [label=ConvolutionBackward0]
	2454389877264 -> 2454389877072
	2454389877264 [label=CatBackward0]
	2454389616896 -> 2454389877264
	2454389873904 -> 2454389877264
	2454389877408 -> 2454389877264
	2454389877408 [label=UpsampleBilinear2DBackward0]
	2454389877504 -> 2454389877408
	2454389877504 [label=ReluBackward0]
	2454389877600 -> 2454389877504
	2454389877600 [label=NativeBatchNormBackward0]
	2454389877696 -> 2454389877600
	2454389877696 [label=ConvolutionBackward0]
	2454389877888 -> 2454389877696
	2454389877888 [label=ReluBackward0]
	2454389878032 -> 2454389877888
	2454389878032 [label=NativeBatchNormBackward0]
	2454389878128 -> 2454389878032
	2454389878128 [label=ConvolutionBackward0]
	2454389878320 -> 2454389878128
	2454389878320 [label=CatBackward0]
	2454389875536 -> 2454389878320
	2454389878464 -> 2454389878320
	2454389878464 [label=UpsampleBilinear2DBackward0]
	2454389878560 -> 2454389878464
	2454389878560 [label=ReluBackward0]
	2454389878656 -> 2454389878560
	2454389878656 [label=NativeBatchNormBackward0]
	2454389878752 -> 2454389878656
	2454389878752 [label=ConvolutionBackward0]
	2454389878944 -> 2454389878752
	2454389878944 [label=ReluBackward0]
	2454389879088 -> 2454389878944
	2454389879088 [label=NativeBatchNormBackward0]
	2454389879184 -> 2454389879088
	2454389879184 [label=ConvolutionBackward0]
	2454389879376 -> 2454389879184
	2454389879376 [label=MaxPool2DWithIndicesBackward0]
	2454389875536 -> 2454389879376
	2454389879328 -> 2454389879184
	2452443741248 [label="rows.3.0.conv.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2452443741248 -> 2454389879328
	2454389879328 [label=AccumulateGrad]
	2454389879136 -> 2454389879088
	2452443741328 [label="rows.3.0.conv.1.weight
 (256)" fillcolor=lightblue]
	2452443741328 -> 2454389879136
	2454389879136 [label=AccumulateGrad]
	2454389878992 -> 2454389879088
	2452443741408 [label="rows.3.0.conv.1.bias
 (256)" fillcolor=lightblue]
	2452443741408 -> 2454389878992
	2454389878992 [label=AccumulateGrad]
	2454389878896 -> 2454389878752
	2452443741888 [label="rows.3.0.conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2452443741888 -> 2454389878896
	2454389878896 [label=AccumulateGrad]
	2454389878704 -> 2454389878656
	2452443741968 [label="rows.3.0.conv.4.weight
 (256)" fillcolor=lightblue]
	2452443741968 -> 2454389878704
	2454389878704 [label=AccumulateGrad]
	2454389878368 -> 2454389878656
	2452443742048 [label="rows.3.0.conv.4.bias
 (256)" fillcolor=lightblue]
	2452443742048 -> 2454389878368
	2454389878368 [label=AccumulateGrad]
	2454389878272 -> 2454389878128
	2452443739008 [label="rows.2.1.conv.0.weight
 (128, 384, 3, 3)" fillcolor=lightblue]
	2452443739008 -> 2454389878272
	2454389878272 [label=AccumulateGrad]
	2454389878080 -> 2454389878032
	2452443727968 [label="rows.2.1.conv.1.weight
 (128)" fillcolor=lightblue]
	2452443727968 -> 2454389878080
	2454389878080 [label=AccumulateGrad]
	2454389877936 -> 2454389878032
	2452443734368 [label="rows.2.1.conv.1.bias
 (128)" fillcolor=lightblue]
	2452443734368 -> 2454389877936
	2454389877936 [label=AccumulateGrad]
	2454389877840 -> 2454389877696
	2452443739408 [label="rows.2.1.conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2452443739408 -> 2454389877840
	2454389877840 [label=AccumulateGrad]
	2454389877648 -> 2454389877600
	2452443739488 [label="rows.2.1.conv.4.weight
 (128)" fillcolor=lightblue]
	2452443739488 -> 2454389877648
	2454389877648 [label=AccumulateGrad]
	2454389877312 -> 2454389877600
	2452443739568 [label="rows.2.1.conv.4.bias
 (128)" fillcolor=lightblue]
	2452443739568 -> 2454389877312
	2454389877312 [label=AccumulateGrad]
	2454389877216 -> 2454389877072
	2452443735328 [label="rows.1.2.conv.0.weight
 (64, 256, 3, 3)" fillcolor=lightblue]
	2452443735328 -> 2454389877216
	2454389877216 [label=AccumulateGrad]
	2454389877024 -> 2454389876976
	2452443735408 [label="rows.1.2.conv.1.weight
 (64)" fillcolor=lightblue]
	2452443735408 -> 2454389877024
	2454389877024 [label=AccumulateGrad]
	2454389876880 -> 2454389876976
	2452443735488 [label="rows.1.2.conv.1.bias
 (64)" fillcolor=lightblue]
	2452443735488 -> 2454389876880
	2454389876880 [label=AccumulateGrad]
	2454389876784 -> 2454389876640
	2452443735968 [label="rows.1.2.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2452443735968 -> 2454389876784
	2454389876784 [label=AccumulateGrad]
	2454389876592 -> 2454389876544
	2452443736048 [label="rows.1.2.conv.4.weight
 (64)" fillcolor=lightblue]
	2452443736048 -> 2454389876592
	2454389876592 [label=AccumulateGrad]
	2454389876256 -> 2454389876544
	2452443736128 [label="rows.1.2.conv.4.bias
 (64)" fillcolor=lightblue]
	2452443736128 -> 2454389876256
	2454389876256 [label=AccumulateGrad]
	2454389875776 -> 2454389875584
	2452443730208 [label="rows.0.3.conv.0.weight
 (32, 160, 3, 3)" fillcolor=lightblue]
	2452443730208 -> 2454389875776
	2454389875776 [label=AccumulateGrad]
	2454389874960 -> 2454389875152
	2452443730288 [label="rows.0.3.conv.1.weight
 (32)" fillcolor=lightblue]
	2452443730288 -> 2454389874960
	2454389874960 [label=AccumulateGrad]
	2454389868624 -> 2454389875152
	2452443730368 [label="rows.0.3.conv.1.bias
 (32)" fillcolor=lightblue]
	2452443730368 -> 2454389868624
	2454389868624 [label=AccumulateGrad]
	2454389873952 -> 2454388764208
	2452443730848 [label="rows.0.3.conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2452443730848 -> 2454389873952
	2454389873952 [label=AccumulateGrad]
	2454389874288 -> 2454389618240
	2452443730928 [label="rows.0.3.conv.4.weight
 (32)" fillcolor=lightblue]
	2452443730928 -> 2454389874288
	2454389874288 [label=AccumulateGrad]
	2454389874240 -> 2454389618240
	2452443731008 [label="rows.0.3.conv.4.bias
 (32)" fillcolor=lightblue]
	2452443731008 -> 2454389874240
	2454389874240 [label=AccumulateGrad]
	2454388768432 -> 2454388763440
	2454388768432 [label=UpsampleBilinear2DBackward0]
	2454389614784 -> 2454388768432
	2454389614784 [label=ReluBackward0]
	2454389875488 -> 2454389614784
	2454389875488 [label=NativeBatchNormBackward0]
	2454389876496 -> 2454389875488
	2454389876496 [label=ConvolutionBackward0]
	2454389876736 -> 2454389876496
	2454389876736 [label=ReluBackward0]
	2454389876928 -> 2454389876736
	2454389876928 [label=NativeBatchNormBackward0]
	2454389877456 -> 2454389876928
	2454389877456 [label=ConvolutionBackward0]
	2454389878224 -> 2454389877456
	2454389878224 [label=CatBackward0]
	2454389616896 -> 2454389878224
	2454389873904 -> 2454389878224
	2454389876448 -> 2454389878224
	2454389878608 -> 2454389878224
	2454389878608 [label=UpsampleBilinear2DBackward0]
	2454389878416 -> 2454389878608
	2454389878416 [label=ReluBackward0]
	2454389878848 -> 2454389878416
	2454389878848 [label=NativeBatchNormBackward0]
	2454389879232 -> 2454389878848
	2454389879232 [label=ConvolutionBackward0]
	2454389879520 -> 2454389879232
	2454389879520 [label=ReluBackward0]
	2454389879664 -> 2454389879520
	2454389879664 [label=NativeBatchNormBackward0]
	2454389879760 -> 2454389879664
	2454389879760 [label=ConvolutionBackward0]
	2454389879952 -> 2454389879760
	2454389879952 [label=CatBackward0]
	2454389875536 -> 2454389879952
	2454389877504 -> 2454389879952
	2454389880096 -> 2454389879952
	2454389880096 [label=UpsampleBilinear2DBackward0]
	2454389880192 -> 2454389880096
	2454389880192 [label=ReluBackward0]
	2454389880288 -> 2454389880192
	2454389880288 [label=NativeBatchNormBackward0]
	2454389880384 -> 2454389880288
	2454389880384 [label=ConvolutionBackward0]
	2454389880576 -> 2454389880384
	2454389880576 [label=ReluBackward0]
	2454389880720 -> 2454389880576
	2454389880720 [label=NativeBatchNormBackward0]
	2454389880816 -> 2454389880720
	2454389880816 [label=ConvolutionBackward0]
	2454389881008 -> 2454389880816
	2454389881008 [label=CatBackward0]
	2454389878560 -> 2454389881008
	2454389881152 -> 2454389881008
	2454389881152 [label=UpsampleBilinear2DBackward0]
	2454389881248 -> 2454389881152
	2454389881248 [label=ReluBackward0]
	2454389881344 -> 2454389881248
	2454389881344 [label=NativeBatchNormBackward0]
	2454389881440 -> 2454389881344
	2454389881440 [label=ConvolutionBackward0]
	2454389881632 -> 2454389881440
	2454389881632 [label=ReluBackward0]
	2454389881776 -> 2454389881632
	2454389881776 [label=NativeBatchNormBackward0]
	2454389881872 -> 2454389881776
	2454389881872 [label=ConvolutionBackward0]
	2454389882064 -> 2454389881872
	2454389882064 [label=MaxPool2DWithIndicesBackward0]
	2454389878560 -> 2454389882064
	2454389882016 -> 2454389881872
	2452443989552 [label="rows.4.0.conv.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2452443989552 -> 2454389882016
	2454389882016 [label=AccumulateGrad]
	2454389881824 -> 2454389881776
	2452443989632 [label="rows.4.0.conv.1.weight
 (512)" fillcolor=lightblue]
	2452443989632 -> 2454389881824
	2454389881824 [label=AccumulateGrad]
	2454389881680 -> 2454389881776
	2452443989712 [label="rows.4.0.conv.1.bias
 (512)" fillcolor=lightblue]
	2452443989712 -> 2454389881680
	2454389881680 [label=AccumulateGrad]
	2454389881584 -> 2454389881440
	2452443990192 [label="rows.4.0.conv.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2452443990192 -> 2454389881584
	2454389881584 [label=AccumulateGrad]
	2454389881392 -> 2454389881344
	2452443990272 [label="rows.4.0.conv.4.weight
 (512)" fillcolor=lightblue]
	2452443990272 -> 2454389881392
	2454389881392 [label=AccumulateGrad]
	2454389881056 -> 2454389881344
	2452443990352 [label="rows.4.0.conv.4.bias
 (512)" fillcolor=lightblue]
	2452443990352 -> 2454389881056
	2454389881056 [label=AccumulateGrad]
	2454389880960 -> 2454389880816
	2452443988272 [label="rows.3.1.conv.0.weight
 (256, 768, 3, 3)" fillcolor=lightblue]
	2452443988272 -> 2454389880960
	2454389880960 [label=AccumulateGrad]
	2454389880768 -> 2454389880720
	2452443988352 [label="rows.3.1.conv.1.weight
 (256)" fillcolor=lightblue]
	2452443988352 -> 2454389880768
	2454389880768 [label=AccumulateGrad]
	2454389880624 -> 2454389880720
	2452443988432 [label="rows.3.1.conv.1.bias
 (256)" fillcolor=lightblue]
	2452443988432 -> 2454389880624
	2454389880624 [label=AccumulateGrad]
	2454389880528 -> 2454389880384
	2452443988912 [label="rows.3.1.conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2452443988912 -> 2454389880528
	2454389880528 [label=AccumulateGrad]
	2454389880336 -> 2454389880288
	2452443988992 [label="rows.3.1.conv.4.weight
 (256)" fillcolor=lightblue]
	2452443988992 -> 2454389880336
	2454389880336 [label=AccumulateGrad]
	2454389880000 -> 2454389880288
	2452443989072 [label="rows.3.1.conv.4.bias
 (256)" fillcolor=lightblue]
	2452443989072 -> 2454389880000
	2454389880000 [label=AccumulateGrad]
	2454389879904 -> 2454389879760
	2452443739968 [label="rows.2.2.conv.0.weight
 (128, 512, 3, 3)" fillcolor=lightblue]
	2452443739968 -> 2454389879904
	2454389879904 [label=AccumulateGrad]
	2454389879712 -> 2454389879664
	2452443740048 [label="rows.2.2.conv.1.weight
 (128)" fillcolor=lightblue]
	2452443740048 -> 2454389879712
	2454389879712 [label=AccumulateGrad]
	2454389879568 -> 2454389879664
	2452443740128 [label="rows.2.2.conv.1.bias
 (128)" fillcolor=lightblue]
	2452443740128 -> 2454389879568
	2454389879568 [label=AccumulateGrad]
	2454389879472 -> 2454389879232
	2452443740608 [label="rows.2.2.conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2452443740608 -> 2454389879472
	2454389879472 [label=AccumulateGrad]
	2454389879280 -> 2454389878848
	2452443740688 [label="rows.2.2.conv.4.weight
 (128)" fillcolor=lightblue]
	2452443740688 -> 2454389879280
	2454389879280 [label=AccumulateGrad]
	2454389878176 -> 2454389878848
	2452443740768 [label="rows.2.2.conv.4.bias
 (128)" fillcolor=lightblue]
	2452443740768 -> 2454389878176
	2454389878176 [label=AccumulateGrad]
	2454389877792 -> 2454389877456
	2452443736528 [label="rows.1.3.conv.0.weight
 (64, 320, 3, 3)" fillcolor=lightblue]
	2452443736528 -> 2454389877792
	2454389877792 [label=AccumulateGrad]
	2454389877552 -> 2454389876928
	2452443736608 [label="rows.1.3.conv.1.weight
 (64)" fillcolor=lightblue]
	2452443736608 -> 2454389877552
	2454389877552 [label=AccumulateGrad]
	2454389877168 -> 2454389876928
	2452443736688 [label="rows.1.3.conv.1.bias
 (64)" fillcolor=lightblue]
	2452443736688 -> 2454389877168
	2454389877168 [label=AccumulateGrad]
	2454389876688 -> 2454389876496
	2452443737168 [label="rows.1.3.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2452443737168 -> 2454389876688
	2454389876688 [label=AccumulateGrad]
	2454389875200 -> 2454389875488
	2452443737248 [label="rows.1.3.conv.4.weight
 (64)" fillcolor=lightblue]
	2452443737248 -> 2454389875200
	2454389875200 [label=AccumulateGrad]
	2454389874864 -> 2454389875488
	2452443737328 [label="rows.1.3.conv.4.bias
 (64)" fillcolor=lightblue]
	2452443737328 -> 2454389874864
	2454389874864 [label=AccumulateGrad]
	2454388762288 -> 2454388763104
	2452443731488 [label="rows.0.4.conv.0.weight
 (32, 192, 3, 3)" fillcolor=lightblue]
	2452443731488 -> 2454388762288
	2454388762288 [label=AccumulateGrad]
	2454388767088 -> 2454388765936
	2452443731568 [label="rows.0.4.conv.1.weight
 (32)" fillcolor=lightblue]
	2452443731568 -> 2454388767088
	2454388767088 [label=AccumulateGrad]
	2454388762864 -> 2454388765936
	2452443731648 [label="rows.0.4.conv.1.bias
 (32)" fillcolor=lightblue]
	2452443731648 -> 2454388762864
	2454388762864 [label=AccumulateGrad]
	2454388762000 -> 2454388753408
	2452443732128 [label="rows.0.4.conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2452443732128 -> 2454388762000
	2454388762000 [label=AccumulateGrad]
	2454388764160 -> 2454388766032
	2452443732208 [label="rows.0.4.conv.4.weight
 (32)" fillcolor=lightblue]
	2452443732208 -> 2454388764160
	2454388764160 [label=AccumulateGrad]
	2454388768528 -> 2454388766032
	2452443732288 [label="rows.0.4.conv.4.bias
 (32)" fillcolor=lightblue]
	2452443732288 -> 2454388768528
	2454388768528 [label=AccumulateGrad]
	2454388766128 -> 2454388753552
	2452443990832 [label="output.weight
 (3, 32, 1, 1)" fillcolor=lightblue]
	2452443990832 -> 2454388766128
	2454388766128 [label=AccumulateGrad]
	2454388766416 -> 2454388753552
	2452443990912 [label="output.bias
 (3)" fillcolor=lightblue]
	2452443990912 -> 2454388766416
	2454388766416 [label=AccumulateGrad]
	2454388753552 -> 2452443995712
}
